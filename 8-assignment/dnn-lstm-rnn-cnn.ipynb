{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport keras\nimport pandas\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.preprocessing import LabelEncoder\n\nnp.random.seed(3)\n\n# number of wine classes\nclassifications = 3\n\n# load dataset\ndataset = np.loadtxt('../input/dataset2/dataset2(3).csv', delimiter=\",\")\n\n# split dataset into sets for testing and training\nX = dataset[:,1:3]\nY = dataset[:,0:1]\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=5)\n\n# convert output values to one-hot\ny_train = keras.utils.np_utils.to_categorical(y_train-1, classifications)\ny_test = keras.utils.np_utils.to_categorical(y_test-1, classifications)\n\n# creating model\nmodel = Sequential()\nmodel.add(Dense(60, input_dim=2, activation='relu'))\nmodel.add(Dropout(0.20))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dropout(0.20))\nmodel.add(Dense(40, activation='relu'))\nmodel.add(Dropout(0.20))\nmodel.add(Dense(30, activation='relu'))\nmodel.add(Dropout(0.20))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dropout(0.20))\n#model.add(Dense(5, activation='relu'))\n#model.add(Dense(classifications, activation='softmax'))\nmodel.add(Dense(classifications, activation='sigmoid'))\nmodel.summary()\n# compile and fit model\n#model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n#model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\nhistory = model.fit(x_train, y_train, batch_size=15, epochs=50, validation_data=(x_test, y_test))\nprint(history.history.keys())\npred = model.predict(x_test)\npred = np.argmax(pred, axis=1)\ny_test2 = np.argmax(y_test, axis=1)\ncm = confusion_matrix(y_test2, pred)\nnp.set_printoptions(precision = 2)\nprint('confusion matrix without normalization')\nprint(cm)\n\nfig, ax = plt.subplots()\nim = ax.imshow(cm, cmap=plt.get_cmap('hot'), interpolation='nearest',\n               vmin=0, vmax=1)\nfig.colorbar(im)\nplt.show()\n#skplt.metrics.plot_confusion_matrix(cm)\n\n#fig, ax = plot_confusion_matrix(conf_mat=cm,\n#                           colorbar=True,\n#                           show_absolute=False,\n#                         show_normed=True)\n\n#plt.imshow(cm)\nplt.figure()\ncm_normalized = cm.astype('float') / cm.sum(axis=1) [:, np.newaxis]\nprint('confusion matrix with normalization')\nprint(cm_normalized)\nprint(y_test2)\nprint(pred)\n\n#print(metrics.roc_auc_score(y_test2, pred))\n#plt.plot(metrics.roc_auc_score)\n#plt.imshow(cm_normalized)\nplt.figure()\n\n#tn, fp, fn, tp = confusion_matrix(y_test2, pred).ravel()\n\n#print(\"True Negatives: \",tn)\n#print(\"False Positives: \",fp)\n#print(\"False Negatives: \",fn)\n#print(\"True Positives: \",tp)\nprint('results')\nprint('Accuracy Score :'), accuracy_score(y_test2, pred)\nprint('Report : ')\nprint(classification_report(y_test2, pred))\n#cr = classification_report(y_test2, pred)\n#plot_classification_report(cr)\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# Get training and test loss histories\ntraining_loss = history.history['loss']\ntest_loss = history.history['val_loss']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss) + 1)\n\n# Visualize loss history\nplt.plot(epoch_count, training_loss, 'r--')\nplt.plot(epoch_count, test_loss, 'b-')\nplt.legend(['Training Loss', 'Test Loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show();\n\nplt.plot(y_test2, label=\"y-original\")\nplt.plot(pred, label=\"y-predicted\")\nplt.legend()\nplt.show()\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-20T05:36:06.434506Z","iopub.execute_input":"2022-03-20T05:36:06.434994Z","iopub.status.idle":"2022-03-20T05:36:55.530707Z","shell.execute_reply.started":"2022-03-20T05:36:06.434909Z","shell.execute_reply":"2022-03-20T05:36:55.530022Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport keras\n#import tensorflow as tf\nimport pandas\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.layers import Embedding, LSTM\nfrom keras.layers import Conv1D, Flatten, MaxPooling1D\nfrom keras import layers\n\n\n\n\nnp.random.seed(3)\n\n# number of wine classes\nclassifications = 2\n\ndata_dim = 2\ntimesteps = 1\n\n# load dataset\ndataset = np.loadtxt('../input/dataset2/dataset2(3).csv', delimiter=\",\")\n\n# split dataset into sets for testing and training\nX = dataset[:,1:3]\nY = dataset[:,0:1]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n\n#print(x_train.shape,y_train.shape)\n#print(x_test.shape,y_test.shape)\n#x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n\nX_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\nX_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n\n# convert output values to one-hot\ny_train = keras.utils.np_utils.to_categorical(y_train-1, classifications)\ny_test = keras.utils.np_utils.to_categorical(y_test-1, classifications)\n\n\n# creating model\n#model = Sequential()\n#model.add(Dense(100, input_dim=3, activation='relu'))\n#model.add(Dropout(0.3))\n#model.add(Dense(80, activation='relu'))\n#model.add(Dropout(0.3))\n#model.add(Dense(50, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(50, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(20, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(10, activation='relu'))\n#model.add(Embedding(vocab_size, 10000, input_length=max_length))\n\n#model.add(Dense(100, input_dim=3, activation='relu'))\n#model.add(Conv1D(filters=32, kernel_size=8, activation='relu', input_shape = (407, 1, 1627, 3)))\n#model.add(Conv1D(128, 8, activation='relu', input_shape= 3))\n#model.add(MaxPooling1D(pool_size=2))\n\n#model.add(Dense(100, input_dim=3, activation='relu'))\nmodel = Sequential()\nmodel.add(LSTM(80, input_shape=(timesteps, data_dim), activation='relu', return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(70, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(60, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(50, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(40, activation='relu'))\n#model.add(Dropout(0.2))\nmodel.add(Dense(20, activation= 'relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(10, activation= 'relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(8, activation= 'relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(80, activation='relu'))\n#model.add(Dense(50, activation='relu'))\n#model.add(Dense(20, activation='relu'))\n#model.add(Flatten())\n#model.add(Dense(classifications, activation='softmax'))\nmodel.add(Dense(classifications, activation='sigmoid'))\n\n# compile and fit model\n#model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n#model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, batch_size=15, epochs=50, validation_data=(X_test, y_test))\n#history = model.fit(X_train, y_train, batch_size=15, epochs=20, validation_split= 0.2)\nprint(history.history.keys())\npred = model.predict(X_test)\npred = np.argmax(pred, axis=1)\ny_test2 = np.argmax(y_test, axis=1)\ncm = confusion_matrix(y_test2, pred)\nnp.set_printoptions(precision = 2)\nprint('confusion matrix without normalization')\nprint(cm)\n\nfig, ax = plt.subplots()\nim = ax.imshow(cm, cmap=plt.get_cmap('hot'), interpolation='nearest',\n               vmin=0, vmax=1)\nfig.colorbar(im)\nplt.show()\n#skplt.metrics.plot_confusion_matrix(cm)\n\n#fig, ax = plot_confusion_matrix(conf_mat=cm,\n#                           colorbar=True,\n#                           show_absolute=False,\n#                         show_normed=True)\n\n#plt.imshow(cm)\nplt.figure()\ncm_normalized = cm.astype('float') / cm.sum(axis=1) [:, np.newaxis]\nprint('confusion matrix with normalization')\nprint(cm_normalized)\nprint(y_test2)\nprint(pred)\n\n#print(metrics.roc_auc_score(y_test2, pred))\n#plt.plot(metrics.roc_auc_score)\n#plt.imshow(cm_normalized)\nplt.figure()\n\n#tn, fp, fn, tp = confusion_matrix(y_test2, pred).ravel()\n\n#print(\"True Negatives: \",tn)\n#print(\"False Positives: \",fp)\n#print(\"False Negatives: \",fn)\n#print(\"True Positives: \",tp)\nprint('results')\nprint('Accuracy Score :'), accuracy_score(y_test2, pred)\nprint('Report : ')\nprint(classification_report(y_test2, pred))\n#cr = classification_report(y_test2, pred)\n#plot_classification_report(cr)\nprint(history.history.keys())\n\n# summarize history for accuracy\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n\n# Get training and test loss histories\ntraining_loss = history.history['loss']\ntest_loss = history.history['val_loss']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss) + 1)\n\n# Visualize loss history\nplt.plot(epoch_count, training_loss, 'r--')\nplt.plot(epoch_count, test_loss, 'b-')\nplt.legend(['Training Loss', 'Test Loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show();\n\nplt.plot(y_test2, label=\"y-original\")\nplt.plot(pred, label=\"y-predicted\")\nplt.legend()\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-20T05:38:51.961306Z","iopub.execute_input":"2022-03-20T05:38:51.961894Z","iopub.status.idle":"2022-03-20T05:42:30.611675Z","shell.execute_reply.started":"2022-03-20T05:38:51.961859Z","shell.execute_reply":"2022-03-20T05:42:30.610979Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport keras\nimport pandas\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors\nfrom matplotlib.colors import ListedColormap\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn import metrics\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.layers import Embedding, LSTM, SimpleRNN\nfrom keras.layers import Conv1D, Flatten, MaxPooling1D\nfrom keras import layers\n\n\n\n\nnp.random.seed(3)\n\n# number of wine classes\nclassifications = 3\n\ndata_dim = 2\ntimesteps = 1\n\n# load dataset\ndataset = np.loadtxt('../input/dataset2/dataset2(3).csv', delimiter=\",\")\n\n# split dataset into sets for testing and training\nX = dataset[:,1:3]\nY = dataset[:,0:1]\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n\n#print(x_train.shape,y_train.shape)\n#print(x_test.shape,y_test.shape)\n#x_train=x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n\nX_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\nX_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n\n# convert output values to one-hot\ny_train = keras.utils.np_utils.to_categorical(y_train-1, classifications)\ny_test = keras.utils.np_utils.to_categorical(y_test-1, classifications)\n\n\n# creating model\n#model = Sequential()\n#model.add(Dense(100, input_dim=3, activation='relu'))\n#model.add(Dropout(0.3))\n#model.add(Dense(80, activation='relu'))\n#model.add(Dropout(0.3))\n#model.add(Dense(50, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(50, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(20, activation='relu'))\n#model.add(Dropout(0.2))\n#model.add(Dense(10, activation='relu'))\n#model.add(Embedding(vocab_size, 10000, input_length=max_length))\n\n#model.add(Dense(100, input_dim=3, activation='relu'))\n#model.add(Conv1D(filters=32, kernel_size=8, activation='relu', input_shape = (407, 1, 1627, 3)))\n#model.add(Conv1D(128, 8, activation='relu', input_shape= 3))\n#model.add(MaxPooling1D(pool_size=2))\n\n#model.add(Dense(100, input_dim=3, activation='relu'))\nmodel = Sequential()\nmodel.add(SimpleRNN(80, input_shape=(timesteps, data_dim), activation='relu', return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(SimpleRNN(70, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(SimpleRNN(60, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(SimpleRNN(50, activation='relu', return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(SimpleRNN(40, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(30, activation= 'relu'))\nmodel.add(Dropout(0.2))\n#model.add(Dense(80, activation='relu'))\n#model.add(Dense(50, activation='relu'))\n#model.add(Dense(20, activation='relu'))\n#model.add(Flatten())\nmodel.add(Dense(classifications, activation='softmax'))\n\n# compile and fit model\n#model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n#model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n\nhistory = model.fit(X_train, y_train, batch_size=15, epochs=30, validation_data=(X_test, y_test))\nprint(history.history.keys())\npred = model.predict(X_test)\npred = np.argmax(pred, axis=1)\ny_test2 = np.argmax(y_test, axis=1)\ncm = confusion_matrix(y_test2, pred)\nnp.set_printoptions(precision = 2)\nprint('confusion matrix without normalization')\nprint(cm)\n\nfig, ax = plt.subplots()\nim = ax.imshow(cm, cmap=plt.get_cmap('hot'), interpolation='nearest',\n               vmin=0, vmax=1)\nfig.colorbar(im)\nplt.show()\n#skplt.metrics.plot_confusion_matrix(cm)\n\n#fig, ax = plot_confusion_matrix(conf_mat=cm,\n#                           colorbar=True,\n#                           show_absolute=False,\n#                         show_normed=True)\n\n#plt.imshow(cm)\nplt.figure()\ncm_normalized = cm.astype('float') / cm.sum(axis=1) [:, np.newaxis]\nprint('confusion matrix with normalization')\nprint(cm_normalized)\nprint(y_test2)\nprint(pred)\n\n#print(metrics.roc_auc_score(y_test2, pred))\n#plt.plot(metrics.roc_auc_score)\n#plt.imshow(cm_normalized)\nplt.figure()\n\n#tn, fp, fn, tp = confusion_matrix(y_test2, pred).ravel()\n\n#print(\"True Negatives: \",tn)\n#print(\"False Positives: \",fp)\n#print(\"False Negatives: \",fn)\n#print(\"True Positives: \",tp)\nprint('results')\nprint('Accuracy Score :'), accuracy_score(y_test2, pred)\nprint('Report : ')\nprint(classification_report(y_test2, pred))\n#cr = classification_report(y_test2, pred)\n#plot_classification_report(cr)\nprint(history.history.keys())\n# summarize history for accuracy\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\n# Get training and test loss histories\ntraining_loss = history.history['loss']\ntest_loss = history.history['val_loss']\n\n# Create count of the number of epochs\nepoch_count = range(1, len(training_loss) + 1)\n\n# Visualize loss history\nplt.plot(epoch_count, training_loss, 'r--')\nplt.plot(epoch_count, test_loss, 'b-')\nplt.legend(['Training Loss', 'Test Loss'])\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.show();\n\nplt.plot(y_test2, label=\"y-original\")\nplt.plot(pred, label=\"y-predicted\")\nplt.legend()\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-20T05:47:20.730413Z","iopub.execute_input":"2022-03-20T05:47:20.730834Z","iopub.status.idle":"2022-03-20T05:48:36.928778Z","shell.execute_reply.started":"2022-03-20T05:47:20.730798Z","shell.execute_reply":"2022-03-20T05:48:36.927957Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom numpy.random import seed\nseed(1)\nimport tensorflow as tf\ntf.random.set_seed(2) \nimport os\nimport seaborn as sn\nimport keras\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Lambda\nfrom keras.layers import Embedding\nfrom keras.datasets import imdb\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom keras.utils.np_utils import to_categorical\nfrom keras import utils as np_utils\nfrom sklearn.preprocessing import Normalizer\nfrom keras.models import Sequential\nfrom keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\nfrom keras.utils import np_utils\nimport numpy as np\nimport h5py\nfrom keras import callbacks\nfrom keras.callbacks import CSVLogger\nfrom keras.layers import LSTM, GRU, SimpleRNN\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\nfrom imblearn.over_sampling import SMOTE\nimport matplotlib as mpl\nimport matplotlib.pylab as plt\nimport pandas as pd\nplt.ion()\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import roc_curve, auc\nfrom scipy import interp \nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report \nfrom sklearn.metrics import accuracy_score \nfrom keras.utils.vis_utils import plot_model\nimport time\n# number of wine classes\nclassifications = 2\nepochs=3\ndimension=1023\n\n########### load dataset################\n\ndataset1 = np.loadtxt('../input/dataset4/dataset(4).csv', delimiter=\",\" )\n#dataset1 = np.loadtxt('E:/DeepLearningModel -Medical Dataset/data/SARS-COV-2 Ct-Scan Dataset-PCA.csv', delimiter=\",\" )\n\nticklabels =['Yes','No']\n\n############# Data Split ################\n\nX = dataset1[:,0:1023]\nY = dataset1[:,1024]\n\n#sm = SMOTE  (random_state=42)\n#X, Y = sm.fit_resample(X, Y)\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=0)\n\n#sm = SMOTE  (random_state=42)\n#x_train, y_train = sm.fit_resample(x_train, y_train)\n##x_test, y_test = sm.fit_resample(x_test, y_test)\n\nY_train = keras.utils.np_utils.to_categorical(y_train-1, classifications)\nY_test = keras.utils.np_utils.to_categorical(y_test-1, classifications)\n\nX_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\nX_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n\n################# Model ####################\nmodel = Sequential()\nmodel.add(Convolution1D(64, 4, padding=\"same\", activation=\"relu\", input_shape=(dimension, 1)))\nmodel.add(MaxPooling1D(pool_size=2, padding='same'))\nmodel.add(Dropout(0.1))\nmodel.add(Convolution1D(128, 4, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling1D(pool_size=2,padding='same'))\nmodel.add(Dropout(0.1))\nmodel.add(Convolution1D(256, 4, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling1D(pool_size=2, padding='same'))\nmodel.add(Dropout(0.1))\n#model.add(Convolution1D(512, 3, padding=\"same\", activation=\"relu\"))\n#model.add(MaxPooling1D(pool_size=2,padding='same'))\n#model.add(Dropout(0.1))\nmodel.add(LSTM(128))\n#model.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(classifications, activation=\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\nmodel.summary()\ncheckpointer = callbacks.ModelCheckpoint(filepath=\"./checkpoint-{epoch:02d}.hdf5\", save_best_only=True, monitor='val_accuracy')\n# csv_logger = CSVLogger('/Users/farhanullah/PycharmProjects/datasets/cnn.csv', separator=',', append=False)\n\nclass TimeHistory(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.times = []\n\n    def on_epoch_begin(self, epoch, logs={}):\n        self.epoch_time_start = time.time()\n\n    def on_epoch_end(self, epoch, logs={}):\n        self.times.append(time.time() - self.epoch_time_start)\n\ntime_callback = TimeHistory()\n\nhistory=model.fit(X_train, Y_train, epochs=epochs,verbose=1,batch_size=32,validation_data=(X_test, Y_test),callbacks=[checkpointer, time_callback])\nprint(time_callback.times)\ntotal=sum(time_callback.times) \nprint(\"Total Time of Training=\")\nprint(\"%.3f\" %total)\nmodel.save(\"./cnn.hdf5\")\nmodel.summary()\n\nprint(history.history.keys())\n\n###############  Plot History ##################\nfig, ax=plt.subplots()\n\nplt.plot(history.history['accuracy'],'b-')\nplt.plot(history.history['val_accuracy'],'r--')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nax.set_xticks(range(0, epochs+4, 50))\nax.xaxis.set_tick_params(labelsize=8)\nax.yaxis.set_tick_params(labelsize=8)\nax.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\nax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\nplt.legend(['train', 'test'], loc='lower right')\nplt.savefig('./model_accuracy.png')\n\nfig, ax=plt.subplots()\n\nplt.plot(history.history['loss'],'y-')\nplt.plot(history.history['val_loss'],'g--')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nax.set_xticks(range(0, epochs+4, 50))\nax.xaxis.set_tick_params(labelsize=8)\nax.yaxis.set_tick_params(labelsize=8)\nax.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\nax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\nplt.legend(['train', 'test'], loc='upper right')\n# plt.savefig('/Users/farhanullah/PycharmProjects/datasets/model_loss.png')\n\n############## Classification Report ########################\nloss, accuracy = model.evaluate(X_test, Y_test)\nprint(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\npredi = model.predict(X_test)\npred = np.argmax(predi, axis=1)\ny_test2 = np.argmax(Y_test, axis=1)\n\ncm = confusion_matrix(y_test2, pred)\nnp.set_printoptions(precision = 2)\ncm_normalized = np.around(cm.astype('float') / cm.sum(axis=1) [:, np.newaxis], decimals=2)\nprint('Report :')\nprint(classification_report(y_test2, pred))\n\n\n############ Confusion Matrix ###############################\nprint('confusion matrix with normalization')\nprint(cm_normalized)\nfig, ax = plt.subplots(figsize = (10,7))\nsn.heatmap(cm_normalized, annot=True,annot_kws={\"size\": 14,\"fontweight\": 'bold'},cmap='Blues',cbar=False) # font size\nplt.ylabel('Actual Label', fontsize = 14)\nplt.xlabel('Predicted Label', fontsize = 14)\nax.set_xticks(np.arange(len(ticklabels))+ 0.3)\nax.set_yticks(np.arange(len(ticklabels))+ 0.3)\nax.set_xticklabels(ticklabels)\nax.set_yticklabels(ticklabels)\nplt.setp(ax.get_xticklabels(), rotation=90,rotation_mode=\"anchor\",ha=\"right\",fontsize=14)\nplt.setp(ax.get_yticklabels(), rotation=360, ha=\"right\",rotation_mode=\"anchor\",fontsize=14)\nfig.tight_layout()\nplt.savefig('./confusion_matrix.png')\n\n\n########### ROC AUC CURVE ####################\n\nfpr = dict()  \ntpr = dict()  \nroc_auc = dict()  \nfor i in range(classifications):  \n    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], predi[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), predi.ravel())  \nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n# Plot all ROC curves\nplt.figure()  \n#plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n#         label='micro-average ROC curve (area = {0:0.2f})'\n#               ''.format(roc_auc[\"micro\"]),\n#         linewidth=2)\nfor i in range(classifications):\n    plt.plot(fpr[i], tpr[i], \n             label='ROC curve of class {0} (area = {1:0.2f})'  ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Roc Curve Analysis')\nplt.legend(loc=\"lower right\")\nplt.savefig('./ruc_auc.png')\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-20T06:14:11.091471Z","iopub.execute_input":"2022-03-20T06:14:11.091921Z","iopub.status.idle":"2022-03-20T06:14:19.048200Z","shell.execute_reply.started":"2022-03-20T06:14:11.091881Z","shell.execute_reply":"2022-03-20T06:14:19.047528Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnp.random.seed(1337)  # for reproducibility\n#import os\n#os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\nimport random\nrandom.seed(12345)\nimport tensorflow as tf\nimport seaborn as sn\nimport keras\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Lambda\nfrom keras.layers import Embedding\nfrom keras.datasets import imdb\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom keras.utils.np_utils import to_categorical\nfrom keras import utils as np_utils\nfrom sklearn.preprocessing import Normalizer\nfrom keras.models import Sequential\nfrom keras.layers import Convolution1D, Dense, Dropout, Flatten, MaxPooling1D\nfrom keras.utils import np_utils\nimport numpy as np\nimport h5py\nfrom keras import callbacks\nfrom keras.callbacks import CSVLogger\nfrom keras.layers import LSTM, GRU, SimpleRNN\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\nfrom imblearn.over_sampling import SMOTE\nimport matplotlib as mpl\nimport matplotlib.pylab as plt\nimport pandas as pd\nplt.ion()\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import roc_curve, auc\nfrom scipy import interp\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom keras.utils.vis_utils import plot_model\n\n# number of wine classes\nclassifications = 2\nepochs = 5\ndimension = 1023\n\n########### load dataset################\n\ndataset1 = np.loadtxt('../input/dataset4/dataset(4).csv', delimiter=\",\" )\n#dataset1 = np.loadtxt('E:/DeepLearningModel -Medical Dataset/data/SARS-COV-2 Ct-Scan Dataset-PCA.csv', delimiter=\",\" )\n\nticklabels = ['Yes', 'No']\n\n############ Data Split ################\n\nX = dataset1[:,0:1023]\nY = dataset1[:,1024]\n\nsm = SMOTE  (random_state=42)\nX, Y = sm.fit_resample(X, Y)\n\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=0)\n\n#sm = SMOTE  (random_state=42)\n#x_train, y_train = sm.fit_resample(x_train, y_train)\n#x_test, y_test = sm.fit_resample(x_test, y_test)\n\nY_train = keras.utils.np_utils.to_categorical(y_train-1, classifications)\nY_test = keras.utils.np_utils.to_categorical(y_test-1, classifications)\n\nX_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))\nX_test = np.reshape(x_test, (x_test.shape[0],x_test.shape[1],1))\n\n################# Model ####################\nmodel = Sequential()\nmodel.add(Convolution1D(64, 3, padding =\"same\", activation=\"relu\",input_shape=(dimension, 1)))\nmodel.add(MaxPooling1D(pool_size = 2, padding='same'))\nmodel.add(Dropout(0.1))\n\n#model.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n#model.add(MaxPooling1D(pool_length=(2)))\n#model.add(Dropout(0.1))\n#model.add(Convolution1D(64, 3, border_mode=\"same\", activation=\"relu\"))\n#model.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n#model.add(Convolution1D(128, 3, border_mode=\"same\", activation=\"relu\"))\n#model.add(MaxPooling1D(pool_length=(2)))\nmodel.add(SimpleRNN(64))\n#model.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.1))\nmodel.add(Dense(classifications, activation=\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",metrics=['accuracy'])\nmodel.summary()\n\ncheckpointer = callbacks.ModelCheckpoint(filepath=\"./checkpoint-{epoch:02d}.hdf5\", save_best_only=True, monitor='val_accuracy')\n# csv_logger = CSVLogger('/Users/farhanullah/PycharmProjects/cnnrnn/cnnn.csv', separator=',', append=False)\n\nhistory=model.fit(X_train, Y_train, epochs=epochs,verbose=1,batch_size=32,validation_data=(X_test, Y_test))\nmodel.save(\"./SARS-COV-2 Ct-Scan Dataset-PCA.hdf5\")\n#plot_model(model, to_file='/Users/farhanullah/PycharmProjects/cnnrnn/model_plot.png', show_shapes=True, show_layer_names=True)\n\n\nprint(history.history.keys())\n\n###############  Plot History ##################\nfig, ax=plt.subplots()\n\nplt.plot(history.history['accuracy'],'b-')\nplt.plot(history.history['val_accuracy'],'r--')\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nax.set_xticks(range(0, epochs+4, 5))\nax.xaxis.set_tick_params(labelsize=8)\nax.yaxis.set_tick_params(labelsize=8)\nax.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\nax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\nplt.legend(['train', 'test'], loc='lower right')\nplt.savefig('./model_accuracy.png')\nfig, ax=plt.subplots()\n\nplt.plot(history.history['loss'],'y-')\nplt.plot(history.history['val_loss'],'g--')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nax.set_xticks(range(0, epochs+4, 5))\nax.xaxis.set_tick_params(labelsize=8)\nax.yaxis.set_tick_params(labelsize=8)\nax.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\nax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\nplt.legend(['train', 'test'], loc='upper right')\nplt.savefig('./model_loss.png')\n\n############## Classification Report ########################\nloss, accuracy = model.evaluate(X_test, Y_test)\nprint(\"\\nLoss: %.2f, Accuracy: %.2f%%\" % (loss, accuracy*100))\npredi = model.predict(X_test)\npred = np.argmax(predi, axis=1)\ny_test2 = np.argmax(Y_test, axis=1)\ncm = confusion_matrix(y_test2, pred)\nnp.set_printoptions(precision = 2)\ncm_normalized = np.around(cm.astype('float') / cm.sum(axis=1) [:, np.newaxis], decimals=2)\nprint('Report :')\nprint(classification_report(y_test2, pred))\n\n\n############ Confusion Matrix ###############################\nprint('confusion matrix with normalization')\nprint(cm_normalized)\nfig, ax = plt.subplots(figsize = (10,7))\nsn.heatmap(cm_normalized, annot=True,annot_kws={\"size\": 6,\"fontweight\": 'bold'},cmap='Blues',cbar=False) # font size\nplt.ylabel('Actual Label', fontsize = 14)\nplt.xlabel('Predicted Label', fontsize = 14)\nax.set_xticks(np.arange(len(ticklabels))+ 0.3)\nax.set_yticks(np.arange(len(ticklabels))+ 0.3)\nax.set_xticklabels(ticklabels)\nax.set_yticklabels(ticklabels)\nplt.setp(ax.get_xticklabels(), rotation=90,rotation_mode=\"anchor\",ha=\"right\")\nplt.setp(ax.get_yticklabels(), rotation=360, ha=\"right\",rotation_mode=\"anchor\")\nfig.tight_layout()\nplt.savefig('./confusion_matrix.png')\n\n########### ROC AUC CURVE ####################\n\nfpr = dict()  \ntpr = dict()  \nroc_auc = dict()  \nfor i in range(classifications):  \n    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], predi[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(Y_test.ravel(), predi.ravel())  \nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n# Plot all ROC curves\nplt.figure()  \n#plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n#         label='micro-average ROC curve (area = {0:0.2f})'\n#               ''.format(roc_auc[\"micro\"]),\n#         linewidth=2)\nfor i in range(classifications):\n    plt.plot(fpr[i], tpr[i], \n             label='ROC curve of class {0} (area = {1:0.2f})'  ''.format(i, roc_auc[i]))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Roc Curve Analysis')\nplt.legend(loc=\"lower right\")\nplt.savefig('./ruc_auc.png')","metadata":{"execution":{"iopub.status.busy":"2022-03-20T06:16:07.937916Z","iopub.execute_input":"2022-03-20T06:16:07.938211Z","iopub.status.idle":"2022-03-20T06:19:01.303969Z","shell.execute_reply.started":"2022-03-20T06:16:07.938181Z","shell.execute_reply":"2022-03-20T06:19:01.303204Z"},"trusted":true},"execution_count":7,"outputs":[]}]}